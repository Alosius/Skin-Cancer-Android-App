#Importing Essential libraries

import tensorflow as tf

from tensorflow import lite

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D,BatchNormalization
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Activation,Dense, Dropout, Flatten, Conv2D, MaxPool2D,MaxPooling2D,GlobalAveragePooling2D, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.applications import ResNet50,inception_v3,nasnet
from sklearn.utils import class_weight
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
import os
from IPython.display import clear_output
from tensorflow import keras
import time
import datetime

import shutil

from tensorflow.compat.v1 import ConfigProto,InteractiveSession

config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)

#Checking the train data

print('number of train samples')
print(len(os.listdir('../input/datatree/train/nv')))
print(len(os.listdir('../input/datatree/train/mel')))
print(len(os.listdir('../input/datatree/train/bkl')))
print(len(os.listdir('../input/datatree/train/bcc')))
print(len(os.listdir('../input/datatree/train/akiec')))
print(len(os.listdir('../input/datatree/train/vasc')))
print(len(os.listdir('../input/datatree/train/df')))
print(len(os.listdir('../input/datatree/train/nod')))

#Creating Data Generator

train_datagen = ImageDataGenerator(rescale=1./255)

x_train = train_datagen.flow_from_directory(
    directory=r'../input/datatree/train/',
    batch_size=32,
    target_size=(224,224),
    class_mode="categorical",
    shuffle=True,
    seed=42
)
train_generator = x_train
class_weights = class_weight.compute_class_weight('balanced', np.unique(train_generator.classes), train_generator.classes)
class_weights = dict(enumerate(class_weights))
print("train_generator class_weights =",  class_weights)

validation_datagen = ImageDataGenerator(rescale=1./255)

x_validation = validation_datagen.flow_from_directory(
    directory=r'../input/datatree/validation/',
    batch_size=32,
    target_size=(224,224),
    class_mode="categorical",
    shuffle=True,
    seed=42
)
validation_generator = x_validation
class_weights_val = class_weight.compute_class_weight('balanced', np.unique(validation_generator.classes), validation_generator.classes)
class_weights_val = dict(enumerate(class_weights_val))
class_weights_val
print("val_generator class_weights =",  class_weights_val)

test_datagen = ImageDataGenerator(rescale=1./255)

x_test = test_datagen.flow_from_directory(
    directory=r'../input/datatree/test/',
    batch_size=32,
    target_size=(224,224),
    class_mode="categorical",
    shuffle=False,
    seed=42
)

test_generator = x_test

num_train_samples = train_generator.n
num_val_samples = validation_generator.n
train_batch_size = 256
val_batch_size = 256


train_steps = np.ceil(num_train_samples / train_batch_size)
val_steps = np.ceil(num_val_samples / val_batch_size)
print(train_steps)
print(val_steps)

#Creating model

lr =0.0001
def create_inception_model2(n_classes=8,learning_rate=lr):
    raw_model = keras.applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', input_shape=(224,224,3), classes=n_classes)
# first: train only the top layers (which were randomly initialized)
# i.e. freeze all convolutional InceptionV3 layers
    #for layer in raw_model.layers:
    #    layer.trainable = False
    full_model = Sequential()
    full_model.add(raw_model)
    full_model.add(GlobalAveragePooling2D())
    full_model.add(Dropout(0.2))
    full_model.add(Dense(512,activation='relu'))
    full_model.add(Dropout(0.1))
    full_model.add(Dense(8, activation = 'softmax'))
    full_model.compile(Adam(lr=learning_rate), loss = 'categorical_crossentropy', metrics = ['accuracy'])
    full_model.summary()
    return full_model

#Training The Model

model = create_inception_model2(n_classes=8,learning_rate=lr)


filepath = "../outputN/weights_part2.h5"
checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, 
                             save_best_only=True, mode='max',save_weights_only=True)

reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=3, 
                                   verbose=1, mode='max', min_lr=0.0001)
                              
callbacks_list = [checkpoint, reduce_lr]

history = model.fit_generator(train_generator, steps_per_epoch=train_steps, 
                            validation_data=validation_generator,
                            validation_steps=val_steps,
                            epochs=50, verbose=1,
                            class_weight = class_weights,
                            shuffle=True,  
                            callbacks=callbacks_list)

#Plotting Graph For Loss And Accuracy

# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()
    
#Saving Model

keras_model1 = "../outputN/SkinCancerI.pb"
keras.models.save_model(model,keras_model1)

#Converting Model To TensorflowLite

keras.backend.clear_session()
converter = tf.lite.TFLiteConverter.from_saved_model(keras_model1)
tflite_model1 = converter.convert()
open("../outputN/model.tflite", "wb").write(tflite_model1)
